# Data-Science-Projects

## 1.Data Cleaning

Data in the real world is almost never clean. Often before doing anything with it, we have to clean it, which can involve many different steps. In this task, the aim is to explore a messy dataset, and correct any issues you may find. This is a required step before any visualization, which will take place in Data Visualisation part.

Below you are given a data set that contains details of a bank's customers. The task here is to use the preprocessing techniques that we've shown in the class to clean and transform this data set.

1. Uni-variate analysis:
    1. Type of each feature
    2. Mean, median, quantiles for continues
    3. Histogram or frequency tables for categorical

2. Find and remove duplicates.

3. Outliers:
    1. Identify the outliers
    2. Choose the correct treatment

4. Missing values:
    1. Identify missing values
    2. Impute missing values 

5. Transform categorical variables 

6. Scale the data set


## 2.Data Visualisation

Note: Before attempting Data Visualisation section, you should have Data Cleaning project as give in one of the files.

You are tasked with doing some exploratory data analysis, which is the first step in building a model to predict churn. Since this process is usually very large, we will look at a subset of

the total plots you would need to complete this.

1. First you should look at the differences in churn rates, split by the different categorical variables. Produce the appropriate visualisation to compare the average    churn rate, split by:

    i. Geography

    ii. Gender

    iii. Tenure

2. We would also like to know how the data is distributed. Some models require features to be normally distributed, and highly skewed variables can affect summary        statistics if left unchecked. Produce the appropriate visualisation for the distribution of:
    i. Geography

    ii. Age

    iii. Credit Score

3. Combine all of the above visualisations into a subplot.

4. Create a bar plot that shows the correlation of each feature with the target.

    4.1. Order the bars so that the feature with the highest correlation is the first bar.

    4.2. Add the correlation value to the top of each bar

    4.3. Add a line to the figure which shows the average correlation (hint: This will require adding an extra trace).
  

## 3.Deep learning Project

**Image classification with the CIFAR10 dataset(included in Keras)**

- Data set of 50,000 images for training and 10,000 for testing
- RGB(fullcolour) images of 32x32 pixels
- Images tagged in 10 different classes

**Objective of the project:**

  - Testing 5(ormore!) different combinations of elements (Network architecture,data augmentationâ€¦)
  - Collecting the results and analysing them
  - Giving a global comparison among the(atleast) 5 combinations
 
## 4.H&M Recommendations System

**END-TO-ENDMACHINELEARNING with colaborative filtering**


**THE DATA SET**

The datasets necessary for the project has been shared with you.

The data is provided by H&M Group. [H&M Group](https://www.hmgroup.com/)is a family of brands and businesses with 53 online markets andapproximately 4,850 stores. Our online store offers shoppers an extensive selection of products to browse through. Butwith too many choices, customers might not quickly find what interests them or what they are looking for, and ultimately,theymightnotmakeapurchase.Toenhancetheshoppingexperience,productrecommendationsarekey.Moreimportantly, helping customers make the right choices also has a positive implications for sustainability, as it reducesreturns,and therebyminimizesemissionsfromtransportation.

**THE ASSIGNMENT**

In this assignment, H&M Group invites you to develop product recommendations based on data from previous transactions,as well as from customer and product meta data.The available metadata spans from simple data,such as garment type and customer age,to text data from product descriptions,to image data from garment images.



## 5.Predicting the risk of heart disease 


**THE DATASET**

The data set necessary for the Project is provide in this file.

The dataset has been obtained by sampling and adapting the original dataset from Kaggle. Each row in thedataset corresponds to a different individual. Some columns are the answers to questions asked to respondentsabout their health status, such as "Do you have serious difficulty walking or climbing stairs?" or "Have yousmoked at least 100 cigarettes in your entire life? The target is the HeartDisease variable, which indicates whether respondents that have ever reported having coronary heart disease(CHD)or my ocardial infarction.

**THE ASSINGMENT**

The implementation of a ML model to **predict a person's probability of having heart disease.** 

## 6.Final Project DSMarket

please reffer to "DSMarket_evaluation.pptx" file in this folder to get a better understanding of the project.
